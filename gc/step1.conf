[global]
task        = UserTask           ; Job uses user written scripts
backend     = local              ; Send to local batch system

[condor]
classaddata = 
	RunAsOwner=True
	InteractiveUser=true
	SingularityImage="/cvmfs/singularity.opensciencegrid.org/bbockelm/cms:rhel7"
	SingularityBindCVMFS=True
jdldata = 
	run_as_owner=True
	Requirements=Target.OpSysAndVer=="CentOS7"

[jobs]
wall time   = 1:00               ; Jobs will take max 1h

[UserTask]
executable  = step1.sh
dataset splitter = FileBoundarySplitter
input files =  eventloop.py ${X509_USER_PROXY}
files per job = 3
dataset =
    2017B_SingleMuon.txt

;       to submit to a particular machine
;	Requirements=TARGET.Machine=="blade-1.tier2"


[storage]
se output files = out.root
se output pattern = job_@MY_JOBID@_@X@
se path = dir:///mnt/hadoop/store/user/${GC_USERNAME}/Hmm/step1/${GC_TASK_ID}/${DATASETPATH}
